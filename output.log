nohup: ignoring input
/home/michaelbezick/.conda/envs/AdvIL_from_videos/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if not hasattr(tensorboard, "__version__") or LooseVersion(
/home/michaelbezick/.conda/envs/AdvIL_from_videos/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ) < LooseVersion("1.15"):
workspace: /home/michaelbezick/Repos/AIL_from_visual_obs/experiments/exp_lail/2025.01.02/1448_GAN_loss=bce,agent=lail,from_dem=false,seed=0,task=walker_walk
Using new encoder
loading expert target: /home/michaelbezick/Repos/AIL_from_visual_obs/expert_policies/snapshot_walker_walk_frame_skip_1.pt
episode_number: 0
episode_number: 1
Average expert reward: 969.9639023882247, Total number of samples: 2000
[-0.04120171  0.09541252 -0.00588702  0.0059008   0.01584771 -0.00749207]
[-0.03903538  0.09472319 -0.0062846   0.00480624  0.01344244 -0.00812199]
[-0.03843341  0.09534904 -0.00902524  0.00783486  0.01892331 -0.00769665]
[-0.0401719   0.09679585 -0.00852721  0.00521297  0.01623963 -0.01449417]
[-0.04154644  0.08692394 -0.01726929  0.01141491  0.0144719  -0.02200459]
[-0.03638277  0.0880366  -0.02320481  0.01771135 -0.00186941 -0.01607469]
[-0.02690551  0.09536168 -0.01545401  0.01949358 -0.00601327 -0.01406216]
[-0.01881398  0.09175697 -0.01390485  0.00864837  0.0096618  -0.00512625]
[-0.01524088  0.09687493 -0.02221742  0.01843018  0.00412511 -0.01688097]
[-0.04347117  0.11036304 -0.00534712  0.031256    0.01999907  0.00031736]
[-0.02955147  0.1111731   0.0031928   0.03484495  0.02442997 -0.00571685]
[-0.01237697  0.10926003 -0.00116035  0.03552014  0.00617828  0.01185325]
[-0.02804662  0.09534592  0.01115409  0.02981448 -0.0165129   0.00848289]
[-0.01323968  0.10165983 -0.01017323  0.04349229 -0.0169697  -0.00456547]
[-0.04113123  0.09968989 -0.01788543  0.02872212 -0.00438965 -0.01146231]
[-0.02550483  0.07529262 -0.01629852 -0.0008643  -0.00227833 -0.01164435]
[-0.03790028  0.0787468  -0.01794068  0.03659165  0.0205095  -0.00035427]
[-0.01188284  0.08235908 -0.0521912   0.03916364  0.03229846 -0.0419751 ]
[-0.01998251  0.05026419 -0.03510729  0.00360848  0.01847714 -0.02583855]
